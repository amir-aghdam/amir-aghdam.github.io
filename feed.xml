<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://amir-aghdam.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://amir-aghdam.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-06T03:25:15+00:00</updated><id>https://amir-aghdam.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">The Age of Prompting: Why Every Engineer Needs to Rethink Software</title><link href="https://amir-aghdam.github.io/blog/2025/the-age-of-prompting-why-every-engineer-needs-to-rethink-software/" rel="alternate" type="text/html" title="The Age of Prompting: Why Every Engineer Needs to Rethink Software"/><published>2025-06-20T00:14:58+00:00</published><updated>2025-06-20T00:14:58+00:00</updated><id>https://amir-aghdam.github.io/blog/2025/the-age-of-prompting-why-every-engineer-needs-to-rethink-software</id><content type="html" xml:base="https://amir-aghdam.github.io/blog/2025/the-age-of-prompting-why-every-engineer-needs-to-rethink-software/"><![CDATA[<blockquote>Weâ€™re not just coding anymoreâ€Šâ€”â€Šweâ€™re prompting, orchestrating, and building alongside AI.</blockquote> <blockquote><em>â€” AndrejÂ Karpathy</em></blockquote> <p>Andrej Karpathy, former Director of AI at Tesla and founding member of OpenAI, recently gave a powerful talk titled <strong>â€œSoftware in the Era of AI.â€</strong> While itâ€™s worth watching in full (link below), hereâ€™s a distilled, structured guide to the <strong>core ideas and takeaways</strong>â€Šâ€”â€Šespecially for ML engineers building at the frontier.</p> <p>ğŸ¥ <strong>Watch the full talk here â†’</strong> <a href="https://www.youtube.com/watch?v=LCEmiRjPEtQ">https://www.youtube.com/watch?v=LCEmiRjPEtQ</a></p> <h3>ğŸ›¡ The Three Generations ofÂ Software</h3> <p>Karpathy introduces a new framework to understand how <strong>software is evolving:</strong></p> <h3>ğŸ”¹ Software 1.0â€Šâ€”â€ŠCode as Instructions</h3> <ul><li>Traditional software: humans write code in languages like Python, C++,Â etc.</li><li>Think: explicit logic, if-statements, loops.</li></ul> <h3>ğŸ”¹ Software 2.0â€Šâ€”â€ŠNeural Nets asÂ Programs</h3> <ul><li>Instead of writing logic, you <strong>train models</strong> using data and optimization.</li><li>The â€œprogramâ€ is now a set of learnedÂ weights.</li></ul> <h3>ğŸ”¹ Software 3.0â€Šâ€”â€ŠPrompts asÂ Programs</h3> <ul><li>You donâ€™t write code or train modelsâ€Šâ€”â€Šyou <strong>prompt</strong> a large language modelÂ (LLM).</li><li>Programming is now in <strong>natural language</strong> likeÂ English.</li></ul> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*TNFzGhLwv9x5DjHsoN-zSg.png"/><figcaption>Karpathyâ€™s framing of Software 1.0 (manual code), 2.0 (neural networks), and 3.0 (prompting LLMs in natural language).</figcaption></figure> <h3>ğŸ’¡ Prompting is Programming</h3> <p>In the Software 3.0 world, <strong>your prompt becomes theÂ program.</strong></p> <p>Example:<br/> To classify sentiment, youÂ can:</p> <ul><li>Write custom codeÂ (1.0)</li><li>Train a classifier (2.0)</li><li>Prompt an LLM: <em>â€œClassify the following review as positive or negativeâ€¦â€</em> (3.0)</li></ul> <p>This shift is not just about convenienceâ€Šâ€”â€Šitâ€™s a <strong>new computing paradigm</strong>.</p> <h3>ğŸ’» LLMs as Operating Systems</h3> <p>Karpathy argues that LLMs arenâ€™t just toolsâ€Šâ€”â€Štheyâ€™re becoming <strong>complex software platforms</strong>, like operating systems.</p> <h3>Similarities toÂ OS:</h3> <ul><li>LLMs orchestrate memory (context windows), compute (token-by-token inference), and I/O (toolÂ use).</li><li>Closed-source models (GPT, Gemini, Claude) resemble Windows/macOS.</li><li>Open-source models (LLaMA, Mistral) are likeÂ Linux.</li><li>LLM-native apps like <strong>Cursor</strong> or <strong>Perplexity</strong> run <em>on top</em> of this OSÂ layer.</li></ul> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*cgkv0ULRZK5GcZv3w1Gmlg.png"/><figcaption>LLMs acting as new operating systemsâ€Šâ€”â€Šorchestrating memory (context), compute (token inference), and I/O (toolÂ use).</figcaption></figure> <h3>ğŸ›  LLM Apps Are Partially Autonomous Systems</h3> <p>Karpathy emphasizes that <strong>the most useful AI applications today arenâ€™t full agents</strong>â€Šâ€”â€Štheyâ€™re <strong>partially autonomous tools</strong>.</p> <h3>Example:</h3> <p><strong>Cursor</strong> is an AI-powered codeÂ editor:</p> <ul><li>You can type manually (human control).</li><li>Or you can highlight code and let the AI rewriteÂ it.</li><li>Or let it modify an entire repo (full autonomy).</li></ul> <p>ğŸ’¡ This creates an <strong>â€œautonomy sliderâ€</strong>: control how much work you give theÂ AI.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*n7Lc5u2M4tGbbUc-Z2boHg.png"/><figcaption>LLM-native apps like Perplexity combine AI logic with familiar GUI controls to keep humans in theÂ loop.</figcaption></figure> <h3>ğŸ§ LLMs Are â€œPeopleÂ Spiritsâ€</h3> <p>Karpathy offers a provocative analogy: LLMs are <strong>â€œpeople spiritsâ€</strong>â€Šâ€”â€Šstochastic simulations of humans with memory, reasoning, and personality.</p> <h3>LLM strengths:</h3> <ul><li>Huge general knowledge</li><li>Superhuman pattern recognition</li></ul> <h3>But also weaknesses:</h3> <ul><li>Hallucinations</li><li>No persistent memory</li><li>Easily manipulated (prompt injections)</li></ul> <p>This makes working with LLMs a <strong>human-AI cooperation game</strong>,Â where:</p> <ul><li>AI generates</li><li>Human verifies</li></ul> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*93dkBZkOy_8gjpEIKOhH4Q.png"/><figcaption>Karpathyâ€™s human-AI collaboration loop: AI generates; humans verifyâ€Šâ€”â€Šand the faster this loop, theÂ better.</figcaption></figure> <h3>ğŸ§° How to Build Great LLMÂ Apps</h3> <p>According to Karpathy, effective LLM apps share 4 common features:</p> <h3>1. Context management</h3> <p>Apps feed LLMs the right info at the right time (e.g. embeddings of your codebase).</p> <h3>2. Multi-LLM orchestration</h3> <p>Use different models for different jobs (chat, retrieval, diffs).</p> <h3>3. Custom GUI for audit &amp;Â control</h3> <p>A good interface lets users <em>see what the AI is doing</em> and approve/reject outputsÂ quickly.</p> <h3>4. AutonomyÂ slider</h3> <p>Let users control how much power the AI getsâ€Šâ€”â€Šfrom autocomplete to repo-wide edits.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*O4QpeNDOo4RC7JC_jdj2iw.png"/><figcaption>Cursor allows developers to slide between manual coding and full AI-driven repo changesâ€Šâ€”â€Ša spectrum of autonomy.</figcaption></figure> <h3>ğŸ§  Design for Speed: Generation + Verification</h3> <p>Karpathy says: <strong>weâ€™re no longer just writing softwareâ€Šâ€”â€Šweâ€™re verifying AI-generated software.</strong></p> <h3>How to speed up the feedbackÂ loop:</h3> <ul><li>Use visual GUIs to inspect results (faster than reading rawÂ text).</li><li>Write <strong>clear, constrained prompts</strong> to reduce failures.</li><li>Avoid mega-diffs; think in smallÂ chunks.</li></ul> <h3>ğŸŒ Build for LLMs, Not JustÂ Humans</h3> <p>A surprising insight: LLMs are now <strong>users of software</strong>. Just like humans orÂ APIs.</p> <h3>What thisÂ means:</h3> <ul><li>Write docs in <strong>LLM-readable formats</strong> (e.g. markdown, JSON).</li><li>Avoid instructions like â€œclick hereâ€â€Šâ€”â€Šreplace with <strong>API calls or shell commands</strong>.</li><li>Add lm.txt files to help LLMs understand your siteâ€™sÂ purpose.</li></ul> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*8psbDHTxGMjC0V9CH23C5A.png"/><figcaption>Designing for agents: Simplified, machine-readable documentation helps LLMs understand and interact with your software.</figcaption></figure> <h3>âœ¨ Vibe Coding: Everyoneâ€™s a Programmer Now</h3> <p>A viral moment from the talk: Karpathyâ€™s coined term <strong>â€œvibeÂ coding.â€</strong></p> <blockquote><em>You donâ€™t know Swift? Doesnâ€™t matter.<br/> Prompt the LLM, copy-paste, tweak,Â repeat.</em></blockquote> <p>He built working iOS and web apps without knowing the languages, just by <strong>â€œvibingâ€ with theÂ LLM</strong>.</p> <p>This changes who can build softwareâ€Šâ€”â€Šand how fast they can doÂ it.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*-ChoWCNWZCdfhFdmFEPaIg.png"/><figcaption>Karpathyâ€™s Menu.appâ€Šâ€”â€Šbuilt by â€˜vibe codingâ€™ an AI prototype without knowing Swift. The future of accessible dev.</figcaption></figure> <h3>âš§ DevOps is Now the Bottleneck</h3> <p>Ironically, the hardest part isnâ€™t codingâ€Šâ€”â€Šitâ€™s all the <strong>non-codeÂ setup</strong>:</p> <ul><li>Auth</li><li>Hosting</li><li>Billing</li><li>Deployment</li></ul> <p>These tasks are still GUI-based and require human clicks. KarpathyÂ asks:</p> <blockquote><em>â€œWhy am I doing this? Let the agents doÂ it!â€</em></blockquote> <p>Early attempts of addressing this issue is creating the <strong>Model Context ProtocolÂ (MCP)</strong>.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*yF1VZC1M1vJDT62v1JpfnA.png"/><figcaption>The rise ofÂ agents</figcaption></figure> <h3>ğŸ“œ Takeaways for ML Engineers</h3> <p>âœ… Learn to work with prompts, not just code<br/>âœ… Develop effective apps by combining GUI + autonomy sliders to keep AI on a leash<br/>âœ… Structure apps around fast generateâ€“verify loops<br/>âœ… Build documentation and UIs that speak toÂ <strong>agents</strong></p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=9c861fe9d60b" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry></feed>