---
layout: about
title: About
permalink: /
subtitle: <b>Researcher in VLMs and Computer Vision</b> @ <a href='https://www.temple.edu/'>Temple University</a>

profile:
  align: right
  image: prof_pic.png
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>📍 Philadelphia, PA, U.S.A.</p>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---


Hey, thanks for stopping by! 👋

I’m a <strong>Master’s student</strong> in the <strong>CS Department</strong> at <strong>Temple University</strong>, wrapping it up at <strong>Summer 2025</strong>. My research focus include <strong>Vision-Language Models (VLMs)</strong>, <strong>Multimodal Learning</strong>, and <strong>Computer Vision</strong>.

My current research centers on zero-shot adaptation of VLMs, with a particular focus on fine-grained video understanding by leveraging the open-set recognition power of image-language models. I’m especially interested in how we can harness the capabilities of LLMs and VLMs responsibly, equipping them with effective workflows to solve high-impact problems.

<blockquote>
<p>“You have to keep LLMs on a leash.” — Andrej Karpathy 🧠</p>
</blockquote>

Previously, I completed a project on active fine-tuning of foundational vision models like DINO, and I bring over two years of hands-on research experience in <strong>image segmentation</strong>, <strong>active learning</strong>, and <strong>VLMs</strong>.</p>

I’m always open to new ideas, collaborations, or just a good conversation. <strong>Feel free to reach out! 📬</strong>
